{"models":[{"model_info":"Model(name='models/chat-bison-001',\n      base_model_id='',\n      version='001',\n      display_name='PaLM 2 Chat (Legacy)',\n      description='A legacy text-only model optimized for chat conversations',\n      input_token_limit=4096,\n      output_token_limit=1024,\n      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n      temperature=0.25,\n      max_temperature=None,\n      top_p=0.95,\n      top_k=40)"},{"model_info":"Model(name='models/text-bison-001',\n      base_model_id='',\n      version='001',\n      display_name='PaLM 2 (Legacy)',\n      description='A legacy model that understands text and generates text as an output',\n      input_token_limit=8196,\n      output_token_limit=1024,\n      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n      temperature=0.7,\n      max_temperature=None,\n      top_p=0.95,\n      top_k=40)"},{"model_info":"Model(name='models/embedding-gecko-001',\n      base_model_id='',\n      version='001',\n      display_name='Embedding Gecko',\n      description='Obtain a distributed representation of a text.',\n      input_token_limit=1024,\n      output_token_limit=1,\n      supported_generation_methods=['embedText', 'countTextTokens'],\n      temperature=None,\n      max_temperature=None,\n      top_p=None,\n      top_k=None)"},{"model_info":"Model(name='models/gemini-1.0-pro-latest',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro Latest',\n      description=('The best model for scaling across a wide range of tasks. This is the latest '\n                   'model.'),\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=0.9,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=None)"},{"model_info":"Model(name='models/gemini-1.0-pro',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro',\n      description='The best model for scaling across a wide range of tasks',\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=0.9,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=None)"},{"model_info":"Model(name='models/gemini-pro',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro',\n      description='The best model for scaling across a wide range of tasks',\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=0.9,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=None)"},{"model_info":"Model(name='models/gemini-1.0-pro-001',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro 001 (Tuning)',\n      description=('The best model for scaling across a wide range of tasks. This is a stable '\n                   'model that supports tuning.'),\n      input_token_limit=30720,\n      output_token_limit=2048,\n      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n      temperature=0.9,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=None)"},{"model_info":"Model(name='models/gemini-1.0-pro-vision-latest',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro Vision',\n      description='The best image understanding model to handle a broad range of applications',\n      input_token_limit=12288,\n      output_token_limit=4096,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=0.4,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=32)"},{"model_info":"Model(name='models/gemini-pro-vision',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.0 Pro Vision',\n      description='The best image understanding model to handle a broad range of applications',\n      input_token_limit=12288,\n      output_token_limit=4096,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=0.4,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=32)"},{"model_info":"Model(name='models/gemini-1.5-pro-latest',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Pro Latest',\n      description='Mid-size multimodal model that supports up to 2 million tokens',\n      input_token_limit=2097152,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-pro-001',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Pro 001',\n      description='Mid-size multimodal model that supports up to 2 million tokens',\n      input_token_limit=2097152,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-pro',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Pro',\n      description='Mid-size multimodal model that supports up to 2 million tokens',\n      input_token_limit=2097152,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-pro-exp-0801',\n      base_model_id='',\n      version='exp-0801',\n      display_name='Gemini 1.5 Pro Experimental 0801',\n      description='Mid-size multimodal model that supports up to 2 million tokens',\n      input_token_limit=2097152,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-pro-exp-0827',\n      base_model_id='',\n      version='exp-0827',\n      display_name='Gemini 1.5 Pro Experimental 0827',\n      description='Mid-size multimodal model that supports up to 2 million tokens',\n      input_token_limit=2097152,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash-latest',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash Latest',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash-001',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash 001',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash-001-tuning',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash 001 Tuning',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=16384,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash-exp-0827',\n      base_model_id='',\n      version='exp-0827',\n      display_name='Gemini 1.5 Flash Experimental 0827',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/gemini-1.5-flash-8b-exp-0827',\n      base_model_id='',\n      version='001',\n      display_name='Gemini 1.5 Flash 8B Experimental 0827',\n      description='Fast and versatile multimodal model for scaling across diverse tasks',\n      input_token_limit=1048576,\n      output_token_limit=8192,\n      supported_generation_methods=['generateContent', 'countTokens'],\n      temperature=1.0,\n      max_temperature=2.0,\n      top_p=0.95,\n      top_k=64)"},{"model_info":"Model(name='models/embedding-001',\n      base_model_id='',\n      version='001',\n      display_name='Embedding 001',\n      description='Obtain a distributed representation of a text.',\n      input_token_limit=2048,\n      output_token_limit=1,\n      supported_generation_methods=['embedContent'],\n      temperature=None,\n      max_temperature=None,\n      top_p=None,\n      top_k=None)"},{"model_info":"Model(name='models/text-embedding-004',\n      base_model_id='',\n      version='004',\n      display_name='Text Embedding 004',\n      description='Obtain a distributed representation of a text.',\n      input_token_limit=2048,\n      output_token_limit=1,\n      supported_generation_methods=['embedContent'],\n      temperature=None,\n      max_temperature=None,\n      top_p=None,\n      top_k=None)"},{"model_info":"Model(name='models/aqa',\n      base_model_id='',\n      version='001',\n      display_name='Model that performs Attributed Question Answering.',\n      description=('Model trained to return answers to questions that are grounded in provided '\n                   'sources, along with estimating answerable probability.'),\n      input_token_limit=7168,\n      output_token_limit=1024,\n      supported_generation_methods=['generateAnswer'],\n      temperature=0.2,\n      max_temperature=None,\n      top_p=1.0,\n      top_k=40)"}]}
